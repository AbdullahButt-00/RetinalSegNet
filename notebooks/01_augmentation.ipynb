{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55a6c7c",
   "metadata": {},
   "source": [
    "# ðŸ”¬ RetinaLiteNet - Augmentation Pipeline\n",
    "\n",
    "### Advanced Data Augmentation Pipeline (Albumentations)\n",
    "\n",
    "- Uses **Albumentations** to apply a diverse set of augmentations for training.\n",
    "- Applied to both **input images** and **corresponding masks** (Blood Vessel & Optic Disc).\n",
    "- **Transformations include**:\n",
    "  - **Flips:** Horizontal and vertical (50% probability each)\n",
    "  - **Geometric:** Shifts, scaling (zooming), rotations, and shearing\n",
    "  - **Noise & Dropout:** Gaussian noise and coarse dropout (randomly masks small patches)\n",
    "  - **Color & Intensity:** CLAHE, brightness/contrast adjustment, gamma, hue/saturation/value shifts\n",
    "  - **Sharpness & Blur:** Sharpening and Gaussian blur\n",
    "  - **Deformations:** Elastic transform, grid distortion, optical distortion\n",
    "  - **Compression:** JPEG compression to simulate real-world artifacts\n",
    "- **Function `augment_data`** applies the pipeline to an image and its two masks simultaneously.\n",
    "- Ensures **masks remain aligned** with the transformed image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32440366",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f87726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haseeb Ali\\.conda\\envs\\mlenv\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb2a06",
   "metadata": {},
   "source": [
    "### Dataset Paths Configuration\n",
    "\n",
    "- Defines the **file paths** for training and testing datasets.  \n",
    "- **DRIVE dataset:**\n",
    "  - Training: `data/DRIVE/training`\n",
    "  - Test: `data/DRIVE/test`\n",
    "- **IOSTAR dataset:**\n",
    "  - Training: `data/aria-hrf-iostar-data/resized-images/IOSTAR/Train`\n",
    "  - Test: `data/aria-hrf-iostar-data/resized-images/IOSTAR/Test`\n",
    "- Paths are stored in variables for **easy access** throughout the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e8b32d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:06:34.553371Z",
     "iopub.status.busy": "2025-11-19T10:06:34.552765Z",
     "iopub.status.idle": "2025-11-19T10:06:34.560068Z",
     "shell.execute_reply": "2025-11-19T10:06:34.559241Z",
     "shell.execute_reply.started": "2025-11-19T10:06:34.553344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset paths (update according to your Kaggle notebook)\n",
    "DRIVE_PATH = 'data/DRIVE'\n",
    "IOSTAR_PATH = 'data/aria-hrf-iostar-data/resized-images/IOSTAR'\n",
    "\n",
    "DRIVE_TRAIN_PATH = os.path.join(DRIVE_PATH, 'training')\n",
    "DRIVE_TEST_PATH = os.path.join(DRIVE_PATH, 'test')\n",
    "IOSTAR_TRAIN_PATH = os.path.join(IOSTAR_PATH, 'Train')  # Adjust if needed\n",
    "IOSTAR_TEST_PATH = os.path.join(IOSTAR_PATH, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8d442",
   "metadata": {},
   "source": [
    "### Data Augmentation Pipeline (Albumentations)\n",
    "\n",
    "- **Purpose:** Apply advanced, paper-inspired augmentations to training images and corresponding masks (blood vessel and optic disc).  \n",
    "- **Augmentation types included:**\n",
    "  - **Geometric:** Horizontal/vertical flips, rotation, shifting, scaling, shearing.\n",
    "  - **Noise/Dropout:** Gaussian noise, coarse dropout.\n",
    "  - **Color/Intensity:** CLAHE, brightness/contrast adjustment, gamma correction, hue/saturation/value shifts.\n",
    "  - **Detail enhancement:** Sharpening, Gaussian blur.\n",
    "  - **Deformations:** Elastic transform, grid distortion, optical distortion.\n",
    "  - **Compression artifacts:** Simulate JPEG compression.\n",
    "- **Function `augment_data`:** Applies the augmentation to an image and both masks simultaneously, returning the transformed image and masks.  \n",
    "- Ensures consistency between **image and masks** during augmentation.  \n",
    "- âœ… Pipeline is ready for use in training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023534fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data augmentation pipeline configured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Haseeb Ali\\AppData\\Local\\Temp\\ipykernel_17744\\2546514348.py:8: UserWarning: Argument 'shear' is not valid and will be ignored.\n",
      "  A.ShiftScaleRotate(\n",
      "C:\\Users\\Haseeb Ali\\AppData\\Local\\Temp\\ipykernel_17744\\2546514348.py:33: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
      "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n"
     ]
    }
   ],
   "source": [
    "# Advanced augmentation using Albumentations (Paper-based)\n",
    "train_transform = A.Compose([\n",
    "    # Flips\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "\n",
    "    # Rotations / Shifts / Zooming / Shearing\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.1, \n",
    "        scale_limit=0.15,     # zooming\n",
    "        rotate_limit=45, \n",
    "        shear=20,             # shearing\n",
    "        p=0.5\n",
    "    ),\n",
    "\n",
    "    # Noise and Dropout\n",
    "    A.GaussNoise(var_limit=(10, 50), p=0.4),        # white noise\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.4),  # dropout\n",
    "\n",
    "    # Histogram Equalization / CLAHE / Brightness / Contrast / Gamma / Saturation\n",
    "    A.CLAHE(p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.4),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.4),  # saturation boosting\n",
    "\n",
    "    # Sharpening\n",
    "    A.Sharpen(alpha=(0.1, 0.3), lightness=(0.8, 1.2), p=0.3),\n",
    "\n",
    "    # Blur\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "\n",
    "    # Elastic deformation\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
    "\n",
    "    # Grid distortion / Optical distortion\n",
    "    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n",
    "    A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=0.3),\n",
    "\n",
    "    # JPEG compression\n",
    "    A.ImageCompression(quality_lower=30, quality_upper=80, p=0.3),\n",
    "], additional_targets={'mask0': 'mask', 'mask1': 'mask'})\n",
    "\n",
    "\n",
    "def augment_data(image, mask_bv, mask_od):\n",
    "    \"\"\"Apply augmentation to image and both masks\"\"\"\n",
    "    augmented = train_transform(\n",
    "        image=image,\n",
    "        mask0=mask_bv,\n",
    "        mask1=mask_od\n",
    "    )\n",
    "    return augmented['image'], augmented['mask0'], augmented['mask1']\n",
    "\n",
    "print(\"âœ… Data augmentation pipeline configured\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa69a47",
   "metadata": {},
   "source": [
    "### Training Data Preparation and Saving\n",
    "\n",
    "- **Purpose:** Load DRIVE and IOSTAR datasets, apply augmentation, and save as images for training/validation.\n",
    "\n",
    "#### Key Steps:\n",
    "1. **DRIVE Data (Blood Vessels):**\n",
    "   - Load original RGB images and BV masks.\n",
    "   - OD masks set to zeros (dummy).\n",
    "   - Apply augmentation 19x per image (if enabled) using the Albumentations pipeline.\n",
    "   - Append both original and augmented samples.\n",
    "\n",
    "2. **IOSTAR Data (Optic Disc):**\n",
    "   - Load RGB images and OD masks.\n",
    "   - BV masks set to zeros (dummy).\n",
    "   - Augment to reach a target of 400 samples per IOSTAR training set.\n",
    "   - Append original and augmented samples.\n",
    "\n",
    "3. **Final Dataset:**\n",
    "   - Convert all images and masks to NumPy arrays.\n",
    "   - Split into training (80%) and validation (20%) sets.\n",
    "   - Save images and masks as PNGs in structured directories (`images/`, `bv_masks/`, `od_masks/`) for both train and val.\n",
    "\n",
    "- **Output:**  \n",
    "  - `X_train_split`, `y_train_bv_split`, `y_train_od_split` â†’ training samples  \n",
    "  - `X_val_split`, `y_val_bv_split`, `y_val_od_split` â†’ validation samples  \n",
    "  - Saved PNG dataset ready for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133975d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:15:18.905850Z",
     "iopub.status.busy": "2025-11-19T10:15:18.905580Z",
     "iopub.status.idle": "2025-11-19T10:16:02.612350Z",
     "shell.execute_reply": "2025-11-19T10:16:02.611563Z",
     "shell.execute_reply.started": "2025-11-19T10:15:18.905831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING DRIVE TRAINING DATA (Blood Vessels)\n",
      "======================================================================\n",
      "Found 20 DRIVE training images\n",
      "âœ… DRIVE loaded: 20 images â†’ 400 samples so far\n",
      "\n",
      "======================================================================\n",
      "LOADING IOSTAR TRAINING DATA (Optic Disc)\n",
      "======================================================================\n",
      "Found 18 IOSTAR training images\n",
      "âœ… IOSTAR loaded exactly 400 samples\n",
      "\n",
      "======================================================================\n",
      "TRAINING DATA SUMMARY\n",
      "======================================================================\n",
      "âœ… Total training samples: 800\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Œ Train/Val split: 640 train | 160 validation\n",
      "\n",
      "ðŸ’¾ Dataset saved as PNG images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imageio\n",
    "\n",
    "# ===================== SAVE AS IMAGES ===================== #\n",
    "def save_dataset_as_images(split_name, images, masks_bv, masks_od):\n",
    "    base = f\"./dataset/drive_iostar_augmented/{split_name}\"\n",
    "    os.makedirs(f\"{base}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{base}/bv_masks\", exist_ok=True)\n",
    "    os.makedirs(f\"{base}/od_masks\", exist_ok=True)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        imageio.imwrite(f\"{base}/images/img_{i}.png\", (images[i] * 255).astype(\"uint8\"))\n",
    "        imageio.imwrite(f\"{base}/bv_masks/mask_{i}.png\", (masks_bv[i].squeeze() * 255).astype(\"uint8\"))\n",
    "        imageio.imwrite(f\"{base}/od_masks/mask_{i}.png\", (masks_od[i].squeeze() * 255).astype(\"uint8\"))\n",
    "\n",
    "# ===================== LOAD DATA FUNCTION ===================== #\n",
    "def load_training_data(drive_path, iostar_path, img_height, img_width, apply_augmentation=True):\n",
    "    \"\"\"\n",
    "    Load combined training data from DRIVE and IOSTAR with proper ground truth:\n",
    "    - DRIVE: Images + BV masks (from 1st_manual) + dummy OD masks\n",
    "    - IOSTAR: Images + dummy BV masks + OD masks (from Labels)\n",
    "    \"\"\"\n",
    "    X_train, y_train_bv, y_train_od = [], [], []\n",
    "    \n",
    "    # ===== LOAD DRIVE TRAINING DATA (for BV segmentation) =====\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING DRIVE TRAINING DATA (Blood Vessels)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    drive_images_path = os.path.join(drive_path, 'images')\n",
    "    drive_masks_path = os.path.join(drive_path, '1st_manual')\n",
    "    \n",
    "    if os.path.exists(drive_images_path) and os.path.exists(drive_masks_path):\n",
    "        drive_imgs = sorted([f for f in os.listdir(drive_images_path) if f.endswith(('.tif', '.png'))])\n",
    "        drive_masks = sorted([f for f in os.listdir(drive_masks_path) if f.endswith(('.gif', '.png'))])\n",
    "        \n",
    "        print(f\"Found {len(drive_imgs)} DRIVE training images\")\n",
    "        \n",
    "        for img_file, mask_file in zip(drive_imgs, drive_masks):\n",
    "            img = Image.open(os.path.join(drive_images_path, img_file)).convert('RGB')\n",
    "            img = np.array(img)\n",
    "            img = resize(img, (img_height, img_width), preserve_range=True, anti_aliasing=True)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            \n",
    "            mask_bv = Image.open(os.path.join(drive_masks_path, mask_file)).convert('L')\n",
    "            mask_bv = np.array(mask_bv)\n",
    "            mask_bv = resize(mask_bv, (img_height, img_width), preserve_range=True, anti_aliasing=False)\n",
    "            mask_bv = (mask_bv > 127).astype(np.float32)\n",
    "            \n",
    "            mask_od = np.zeros((img_height, img_width), dtype=np.float32)\n",
    "\n",
    "            if apply_augmentation:\n",
    "                for _ in range(19):\n",
    "                    aug_img, aug_bv, aug_od = augment_data(\n",
    "                        (img * 255).astype(np.uint8),\n",
    "                        mask_bv,\n",
    "                        mask_od\n",
    "                    )\n",
    "                    X_train.append(aug_img.astype(np.float32) / 255.0)\n",
    "                    y_train_bv.append(np.expand_dims(aug_bv, -1))\n",
    "                    y_train_od.append(np.expand_dims(aug_od, -1))\n",
    "            \n",
    "            X_train.append(img)\n",
    "            y_train_bv.append(np.expand_dims(mask_bv, -1))\n",
    "            y_train_od.append(np.expand_dims(mask_od, -1))\n",
    "        \n",
    "        print(f\"âœ… DRIVE loaded: {len(drive_imgs)} images â†’ {len(X_train)} samples so far\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ DRIVE path not found: {drive_path}\")\n",
    "    \n",
    "    # ===== LOAD IOSTAR TRAINING DATA (for OD segmentation) =====\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING IOSTAR TRAINING DATA (Optic Disc)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    iostar_images_path = os.path.join(iostar_path, 'Images')\n",
    "    iostar_masks_path = os.path.join(iostar_path, 'Labels')\n",
    "\n",
    "    if os.path.exists(iostar_images_path) and os.path.exists(iostar_masks_path):\n",
    "        iostar_imgs = sorted([f for f in os.listdir(iostar_images_path) if f.endswith('.png')])\n",
    "        iostar_masks = sorted([f for f in os.listdir(iostar_masks_path) if f.endswith('.png')])\n",
    "        \n",
    "        print(f\"Found {len(iostar_imgs)} IOSTAR training images\")\n",
    "\n",
    "        TARGET_IOSTAR = 400\n",
    "        NUM_IOSTAR = len(iostar_imgs)\n",
    "        TOTAL_AUG = TARGET_IOSTAR - NUM_IOSTAR\n",
    "\n",
    "        BASE_AUG = TOTAL_AUG // NUM_IOSTAR\n",
    "        EXTRA = TOTAL_AUG % NUM_IOSTAR\n",
    "\n",
    "        for idx, (img_file, mask_file) in enumerate(zip(iostar_imgs, iostar_masks)):\n",
    "            img = Image.open(os.path.join(iostar_images_path, img_file)).convert('RGB')\n",
    "            img = np.array(img)\n",
    "            img = resize(img, (img_height, img_width), preserve_range=True, anti_aliasing=True)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "\n",
    "            mask_bv = np.zeros((img_height, img_width), dtype=np.float32)\n",
    "\n",
    "            mask_od = Image.open(os.path.join(iostar_masks_path, mask_file)).convert('L')\n",
    "            mask_od = np.array(mask_od)\n",
    "            mask_od = resize(mask_od, (img_height, img_width), preserve_range=True, anti_aliasing=False)\n",
    "            mask_od = (mask_od > 127).astype(np.float32)\n",
    "\n",
    "            aug_times = BASE_AUG + (idx < EXTRA)\n",
    "\n",
    "            if apply_augmentation:\n",
    "                for _ in range(int(aug_times)):\n",
    "                    aug_img, aug_bv, aug_od = augment_data(\n",
    "                        (img * 255).astype(np.uint8),\n",
    "                        mask_bv,\n",
    "                        mask_od\n",
    "                    )\n",
    "                    X_train.append(aug_img.astype(np.float32) / 255.0)\n",
    "                    y_train_bv.append(np.expand_dims(aug_bv, -1))\n",
    "                    y_train_od.append(np.expand_dims(aug_od, -1))\n",
    "\n",
    "            X_train.append(img)\n",
    "            y_train_bv.append(np.expand_dims(mask_bv, -1))\n",
    "            y_train_od.append(np.expand_dims(mask_od, -1))\n",
    "\n",
    "        print(f\"âœ… IOSTAR loaded exactly {TARGET_IOSTAR} samples\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ IOSTAR path not found: {iostar_path}\")\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train_bv = np.array(y_train_bv)\n",
    "    y_train_od = np.array(y_train_od)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING DATA SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"âœ… Total training samples: {len(X_train)}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return X_train, y_train_bv, y_train_od\n",
    "\n",
    "# ===================== START DATA CREATION ===================== #\n",
    "\n",
    "X_train, y_train_bv, y_train_od = load_training_data(\n",
    "    DRIVE_TRAIN_PATH,\n",
    "    IOSTAR_TRAIN_PATH,\n",
    "    512,\n",
    "    512,\n",
    "    apply_augmentation=True\n",
    ")\n",
    "\n",
    "indices = np.arange(len(X_train))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_split = X_train[train_idx]\n",
    "X_val_split = X_train[val_idx]\n",
    "y_train_bv_split = y_train_bv[train_idx]\n",
    "y_val_bv_split = y_train_bv[val_idx]\n",
    "y_train_od_split = y_train_od[train_idx]\n",
    "y_val_od_split = y_train_od[val_idx]\n",
    "\n",
    "print(f\"\\nðŸ“Œ Train/Val split: {len(X_train_split)} train | {len(X_val_split)} validation\")\n",
    "\n",
    "save_dataset_as_images(\"train\", X_train_split, y_train_bv_split, y_train_od_split)\n",
    "save_dataset_as_images(\"val\", X_val_split, y_val_bv_split, y_val_od_split)\n",
    "\n",
    "print(\"\\nðŸ’¾ Dataset saved as PNG images\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 589983,
     "sourceId": 1063445,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5759319,
     "sourceId": 9470678,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
